{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNC7SDZM9rMdXScL/l/dd+n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlawnghks/Self-study/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCGZhBjVUJr5",
        "outputId": "deb01e60-1017-482d-9e62-c128f2cfa4b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (5.3.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.1 konlpy-0.6.0\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JzHxBGMUOMG",
        "outputId": "d0614442-5c57-4722-f41a-e073e727f5e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#형태소 = 언어에서 의미를 가진 최소의 단위"
      ],
      "metadata": {
        "id": "rTDfixfbU2mC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from collections import Counter\n",
        "\n",
        "# 분석할 텍스트\n",
        "text = \"\"\"\n",
        "자연어 처리는 컴퓨터 과학과 인공지능의 한 분야로,\n",
        "컴퓨터가 인간의 언어를 이해하고 해석할 수 있도록 하는 기술입니다.\n",
        "텍스트 분석, 기계 번역, 감성 분석 등 다양한 응용 분야가 있습니다.\n",
        "\"\"\"\n",
        "\n",
        "# 형태소 분석기 초기화\n",
        "okt = Okt()\n",
        "\n",
        "# 텍스트를 명사 단위로 토큰화\n",
        "tokens = okt.nouns(text)\n",
        "\n",
        "# 단어의 빈도수 계산\n",
        "word_counts = Counter(tokens)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"단어 빈도수:\")\n",
        "for word, count in word_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fTqbeotUSpl",
        "outputId": "0de2582d-911e-45c1-8639-04b4137e20f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 빈도수:\n",
            "컴퓨터: 2\n",
            "분야: 2\n",
            "분석: 2\n",
            "자연어: 1\n",
            "처리: 1\n",
            "과학: 1\n",
            "인공: 1\n",
            "지능: 1\n",
            "인간: 1\n",
            "언어: 1\n",
            "이해: 1\n",
            "해석: 1\n",
            "수: 1\n",
            "기술: 1\n",
            "텍스트: 1\n",
            "기계: 1\n",
            "번역: 1\n",
            "감성: 1\n",
            "등: 1\n",
            "응용: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from collections import Counter\n",
        "\n",
        "# 분석할 텍스트\n",
        "text = input(\"분석할 텍스트를 입력하세요: \")\n",
        "\n",
        "# 형태소 분석기 초기화\n",
        "okt = Okt()\n",
        "\n",
        "# 텍스트를 명사 단위로 토큰화\n",
        "tokens = okt.nouns(text)\n",
        "\n",
        "# 단어의 빈도수 계산\n",
        "word_counts = Counter(tokens)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"단어 빈도수:\")\n",
        "for word, count in word_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n"
      ],
      "metadata": {
        "id": "50LOmcwUUZBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32ae6377-f2e1-4201-803f-e0497dcdc0fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "분석할 텍스트를 입력하세요: 안녕하세요 반가워요\n",
            "단어 빈도수:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from collections import Counter\n",
        "\n",
        "# 사용자가 입력한 텍스트 받기\n",
        "text = input(\"분석할 문장을 입력하세요: \")\n",
        "\n",
        "# 형태소 분석기 초기화\n",
        "okt = Okt()\n",
        "\n",
        "# 텍스트를 형태소 단위로 분석\n",
        "tokens_with_tags = okt.pos(text)\n",
        "\n",
        "# 단어와 품사 분리\n",
        "tokens = [word for word, tag in tokens_with_tags]\n",
        "tags = {word: tag for word, tag in tokens_with_tags}\n",
        "\n",
        "# 단어의 빈도수 계산\n",
        "word_counts = Counter(tokens)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"\\n단어 빈도수 및 품사:\")\n",
        "for word, count in word_counts.most_common():\n",
        "    print(f\"{word} ({tags[word]}): {count}번\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMTnlZez9D2l",
        "outputId": "afb8395b-4daf-42dd-aa50-7614698e53b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "분석할 문장을 입력하세요: 안녕하세요\n",
            "\n",
            "단어 빈도수 및 품사:\n",
            "안녕하세요 (Adjective): 1번\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "food_data = {\n",
        "    \"매콤하고 달달하다\": \"떡볶이\",\n",
        "    \"달달하고 부드럽다\": \"케이크\",\n",
        "    \"바삭하고 짭짤하다\": \"치킨\",\n",
        "    \"고소하고 쫄깃하다\": \"김밥\",\n",
        "    \"새콤달콤하다\": \"탕수육\",\n",
        "}\n",
        "\n",
        "def predict_food(input_text):\n",
        "    okt = Okt()\n",
        "    tokens_with_tags = okt.pos(input_text)\n",
        "\n",
        "    tokens = [word for word, tag in tokens_with_tags if tag in [\"Adjective\", \"Noun\"]]\n",
        "    print(f\"추출된 키워드: {tokens}\")\n",
        "\n",
        "    for features, food in food_data.items():\n",
        "        feature_tokens = features.split()\n",
        "        if any(token in feature_tokens for token in tokens):\n",
        "            return food\n",
        "\n",
        "    return \"알 수 없는 음식\"\n",
        "\n",
        "text = input(\"음식의 특징을 입력하세요: \")\n",
        "predicted_food = predict_food(text)\n",
        "print(f\"예측된 음식: {predicted_food}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yrOw7sVGrsZ",
        "outputId": "1a2381be-7530-4758-a5c5-2fd0a67fef85"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "음식의 특징을 입력하세요: 매콤해요\n",
            "추출된 키워드: ['매콤']\n",
            "예측된 음식: 알 수 없는 음식\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 추가 및 성능 개선 필요"
      ],
      "metadata": {
        "id": "4jvATA8kHUxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kiwipiepy\n",
        "from kiwipiepy import Kiwi\n",
        "kiwi = Kiwi()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIrP2hU0-kVW",
        "outputId": "7309e423-9c84-4bbd-9cce-7584c6817cea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kiwipiepy\n",
            "  Downloading kiwipiepy-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting kiwipiepy_model<0.21,>=0.20 (from kiwipiepy)\n",
            "  Downloading kiwipiepy_model-0.20.0.tar.gz (34.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from kiwipiepy) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kiwipiepy) (4.67.1)\n",
            "Downloading kiwipiepy-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: kiwipiepy_model\n",
            "  Building wheel for kiwipiepy_model (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kiwipiepy_model: filename=kiwipiepy_model-0.20.0-py3-none-any.whl size=34818026 sha256=58b7d9e59aa4cb28ef554828fd01e844374ad651fa012292290941fc8613a3c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/b1/66/2be9840f8ef3627d63d93503d81a5e3b41e9498dcb63b00b13\n",
            "Successfully built kiwipiepy_model\n",
            "Installing collected packages: kiwipiepy_model, kiwipiepy\n",
            "Successfully installed kiwipiepy-0.20.3 kiwipiepy_model-0.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"이것은 한글 형태소 분석 키위 분석기입니다.\"\n",
        "tokens = kiwi.tokenize(text)"
      ],
      "metadata": {
        "id": "xC7De9aT-2nl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nouns = []\n",
        "for token in kiwi.tokenize(text):\n",
        "    if 'NN' in token.tag:\n",
        "        nouns.append(token.form)"
      ],
      "metadata": {
        "id": "ukSHbZ1h_eQ0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "키위 형태소 분석기 한글 분석을 위해 공부"
      ],
      "metadata": {
        "id": "ogxvpPyEBncr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kiwipiepy\n",
        "from kiwipiepy import Kiwi"
      ],
      "metadata": {
        "id": "wDxWvyPzBnMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb50c993-fcc1-44b0-edfc-6eea9ba1cb45"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kiwipiepy in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: kiwipiepy_model<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from kiwipiepy) (0.20.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from kiwipiepy) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kiwipiepy) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kiwi = Kiwi()\n",
        "\n",
        "text = input(\"분석할 텍스트를 입력하세요: \")\n",
        "\n",
        "tokens = kiwi.analyze(text) #형태소를 단위로 나눔\n",
        "print(\"\\n[1] 형태소 분석 결과:\")\n",
        "for token in tokens[0][0]:\n",
        "    print(f\"{token[0]} ({token[1]})\")\n",
        "\n",
        "stopwords = ['은', '는', '이', '가', '을', '를', '에', '의', '과', '와']  #불용어 제거\n",
        "filtered_tokens = [token[0] for token in tokens[0][0] if token[0] not in stopwords]\n",
        "print(\"\\n[2] 불용어 제거 후:\")\n",
        "print(filtered_tokens)\n",
        "\n",
        "nouns = [token[0] for token in tokens[0][0] if token[1] in ['NNG', 'NNP']]\n",
        "print(\"\\n[3] 텍스트에서 추출된 명사:\")\n",
        "print(nouns)\n",
        "\n",
        "unique_words = sorted(set(filtered_tokens))\n",
        "print(\"\\n[4] 중복 제거된 단어 리스트:\")\n",
        "print(unique_words)"
      ],
      "metadata": {
        "id": "tOQdLwf8ABl9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffffaef2-85e8-4517-c52f-298e04c21c59"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "분석할 텍스트를 입력하세요: 자연어 처리는 인공지능의 한 분야로, 사람의 언어를 이해하고 처리하는 기술입니다.\n",
            "\n",
            "[1] 형태소 분석 결과:\n",
            "자연어 처리 (NNP)\n",
            "는 (JX)\n",
            "인공 (NNG)\n",
            "지능 (NNG)\n",
            "의 (JKG)\n",
            "한 (MM)\n",
            "분야 (NNG)\n",
            "로 (JKB)\n",
            ", (SP)\n",
            "사람 (NNG)\n",
            "의 (JKG)\n",
            "언어 (NNG)\n",
            "를 (JKO)\n",
            "이해 (NNG)\n",
            "하 (XSV)\n",
            "고 (EC)\n",
            "처리 (NNG)\n",
            "하 (XSV)\n",
            "는 (ETM)\n",
            "기술 (NNG)\n",
            "이 (VCP)\n",
            "ᆸ니다 (EF)\n",
            ". (SF)\n",
            "\n",
            "[2] 불용어 제거 후:\n",
            "['자연어 처리', '인공', '지능', '한', '분야', '로', ',', '사람', '언어', '이해', '하', '고', '처리', '하', '기술', 'ᆸ니다', '.']\n",
            "\n",
            "[3] 텍스트에서 추출된 명사:\n",
            "['자연어 처리', '인공', '지능', '분야', '사람', '언어', '이해', '처리', '기술']\n",
            "\n",
            "[4] 중복 제거된 단어 리스트:\n",
            "[',', '.', 'ᆸ니다', '고', '기술', '로', '분야', '사람', '언어', '이해', '인공', '자연어 처리', '지능', '처리', '하', '한']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "불용어 제거,키위 형태소로 코드 만들어 공부"
      ],
      "metadata": {
        "id": "KUZ6G3ok1G4P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gy97iqvrW8y6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}